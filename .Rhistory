x <- 5
x <- x+1
x
print(x)
x <- "intro to r"
y <- TRUE
class(y)
as.numeric(y)
z <- FALSE
as.numeric(z)
vec1 <- c(1,2,3)
vec2 <- c("apple", 2, "banana")
vec2
vec3 <- c(4,3,2,1,3,2,4)
lev <- factor(vec3)
lev
vec3.levels
levels(lev)
vec1 <- c(1,2,3,4,5,6)
vec2 <- 1:6
vec3 <- seq(1,6)
vec4 <- rep(1, 5)
vec4 <- rep(1, 6)
mean(vec1)
sum(vec1)
sd(vec1)
var(vec1)
data <- mtcars
data
?mtcars
class(data)
head(data) # first 6 rows
tail(data) # last 6 rows
colnames(data) # prints diff columns
data$mpg
data$new_col <- 0 # creates new column w name 'new_col' and assigned var '0'
data
data$new_col <- c(1:32)
data
data$mpg == TRUE
data$mpg > 15
data$mpg > 15 & data$mpg <= 17
data$mpg >= 15 || data$mpg <=17
data$mpg >= 15 || data$mpg <= 17
### MATH OPERATORS
data$cyl + 2 # adds 2 to every value
x <- TRUE
as.numeric(x)
greater15 <- data$mpg > 15
greater15
as.numeric(greater15)
### NULL/NaN
data$qsec <- NULL
data
data$new_col <- NULL
data
data$vs <- NA
data
class(NA)
class(TRUE)
is.na(data)
sum(is.na(data))
data$qsec <- mtcars$qsec
data
### INDEXING VECTORS
vec1 <- c(1:6)
vec1[1]
data$cyl[20]
sum(data$cyl)
mean(data$cyl)
sd(data$cyl)
var(data$cyl)
data[2,3] # [row, col]
data[2,] # selects whole second row
data["Mazda"]
data["Mazda RX4 Wag",]
### CREATING VECTORS & MATRICES
vec1 <- c(1,3,5,8)
vec1
# 3 ways to creat a 5x1 vec w elements
vec2 <- 1:5
vec2
vec3 <- seq(1,5)
vec3
vec4 <- c(1,2,3,4,5)
vec4
# how to create a 5x1 vec of all 1s
vec5 <- rep(1,5)
vec5
# creating a matrix
mat1 <- matrix(c(1,7,5,6))
mat1
# creating a matrix
mat1 <- matrix(c(1,7,5,6), nrow=2, ncol=2, byrow=FALSE)
mat1
# creating a matrix
mat1 <- matrix(c(1,7,5,6), nrow=2, ncol=2, byrow=TRUE)
mat1
# creating a matrix
mat1 <- matrix(c(1,7,5,6), nrow=2, ncol=2, byrow=T)
mat1
# how R tells us len of vectors and dimensions of matrices
length(vec5)
dim(mat1)
dim(mat1)
# transposing a matrix, flipping along diagnol
# A^T
t(mat1)
mat2
mat2 <- matrix(c(1,2,3,4,5,6), nrow=3,byrow=T)
mat2
t(mat2)
# symmetric matrix
# A = A^T --> if flipped, would be same
# ex. [[1,7],[7,6]]
mat3 <- matrix(c(3,5,5,6), byrow=T, nrow=2)
mat3
solve(mat1)
mat1 * matrix(c(1,7,5,6), nrow=2, ncol=2, byrow=T)
mat1
2*mat1
# scalar multiplication
# CODE: *
mat1+mat1
mat1-mat1
# scalar multiplication
# CODE: *
7*mat1
# scalar multiplication
# CODE: *
mat1*7
# matrix multiplication
# if matrix of [A, B], second matrix must be [B,C] ==> near factor must be in common
# what stays after multiplication is vector of dim [A,C]
# num of col in matrix A must be same as num of rows in matrix B; resulting matrix
# will have num of rows in matrix A and num of col in matrix B
# if A is n x m, B is m x p, C = A*B, where C is n x p ==> could not do B*A
# dot product: multiply each corresponding element and sum individual products
# rows of A by columns of B
# CODE: %*%
mat1
mat2
# matrix multiplication
# if matrix of [A, B], second matrix must be [B,C] ==> near factor must be in common
# what stays after multiplication is vector of dim [A,C]
# num of col in matrix A must be same as num of rows in matrix B; resulting matrix
# will have num of rows in matrix A and num of col in matrix B
# if A is n x m, B is m x p, C = A*B, where C is n x p ==> could not do B*A
# dot product: multiply each corresponding element and sum individual products
# rows of A by columns of B
# CODE: %*%
mat1%*%mat2
# matrix multiplication
# if matrix of [A, B], second matrix must be [B,C] ==> near factor must be in common
# what stays after multiplication is vector of dim [A,C]
# num of col in matrix A must be same as num of rows in matrix B; resulting matrix
# will have num of rows in matrix A and num of col in matrix B
# if A is n x m, B is m x p, C = A*B, where C is n x p ==> could not do B*A
# dot product: multiply each corresponding element and sum individual products
# rows of A by columns of B
# CODE: %*%
mat2%*%mat1
# matrix multiplication
# if matrix of [A, B], second matrix must be [B,C] ==> near factor must be in common
# what stays after multiplication is vector of dim [A,C]
# num of col in matrix A must be same as num of rows in matrix B; resulting matrix
# will have num of rows in matrix A and num of col in matrix B
# if A is n x m, B is m x p, C = A*B, where C is n x p ==> could not do B*A
# dot product: multiply each corresponding element and sum individual products
# rows of A by columns of B
# CODE: %*%
dim(mat2%*%mat1)
data(iris)
head(iris)
iris.l <- iris(iris$Species != "setosa", c(1,3))
iris.l <- iris[iris$Species != "setosa", c(1,3)]
iris.l
head(iris.l)
View(iris.l)
plot(iris.l$Sepal.Length, iris.l$Petal.Length)
corr(iris.l$Sepal.Length, iris.l$Petal.Length)
cor(iris.l$Sepal.Length, iris.l$Petal.Length)
lm(Petal.Length~Sepal.Length, iris.l) # lm(Y~X, data)
lm(Petal.Length~Sepal.Length, data=iris.l) # lm(Y~X, data)
lm(Petal.Length~Sepal.Length, iris.l) # lm(Y~X, data)
iris.lm <- lm(Petal.Length~Sepal.Length, iris.l) # lm(Y~X, data)
iris.lm
summary(iris.lm)
abline(iris.lm)
predict(iris.lm, data.frame(Sepal.Length = 6.0))
predict(iris.lm, data.frame(Sepal.Length = 4.0))
predict(iris.lm, data.frame(Sepal.Length = 9.0))
predict(iris.lm, data.frame(Sepal.Length = 6.0), interval = "confidence")
predict(iris.lm, data.frame(Sepal.Length = 6.0), interval= "prediction")
data(iris)
head(iris)
iris.l <- iris[iris$Species != "setosa", c(1,3)]
head(iris.l)
plot(iris.l$Sepal.Length, iris.l$Petal.Length)
abline(iris.lm)
cor(iris.l$Sepal.Length, iris.l$Petal.Length) # if strongly corr or not
iris.lm <- lm(Petal.Length~Sepal.Length, iris.l) # lm(Y~X, data)
summary(iris.lm)
predict(iris.lm, data.frame(Sepal.Length = 6.0))
predict(iris.lm, data.frame(Sepal.Length = 9.0)) # extrapolates
predict(iris.lm, data.frame(Sepal.Length = 6.0), interval = "confidence")
predict(iris.lm, data.frame(Sepal.Length = 6.0), interval= "prediction")
plot(iris.lm)
# 1. normal dist test
shapiro.test(iris.lm$residuals)
# 2. constant variance test
library(lmtest)
install.packages("lmtest")
# 2. constant variance test
library(lmtest)
bptest(iris.lm, studentize=F)
install.packages("snpar")
# 3. ind/rand test
library(snpar)
# 4. linearity test [look at scatterplot]
plot(iris.l$Sepal.length, iris.l$Petal.length)
# 4. linearity test [look at scatterplot]
plot(iris.l$Sepal.Length, iris.l$Petal.Length)
plot(iris.lm) # check for the above assumptions
## Outliers
# check normal QQ plot that we looked at
plot(iris.lm, 2)
rstandard(iris.lm)
rs[rs==2]
rs <- rstandard(iris.lm) # standardized residuals for all values
rs[rs==2]
rs[rs>=2]
rs[rs>=2]
rs[rs<=2]
rs[rs<=-2]
rs[rs>=2]
summary(influence.measures(iris.lm))
iris.l <- iris[iris$Species!="setosa",c(1,3)]
head(iris.l)
iris.lm <- lm(Petal.Length ~ Sepal.Length, data = iris.l)
summary(iris.lm)
library(shiny); runApp('Desktop/MDI/testapp/histogram.R')
runApp('Desktop/MDI/testapp/MLgolf.r')
runApp('Desktop/MDI/testapp/MLgolf.r')
shiny::runApp('Desktop/MDI/NHSAdash')
runApp('Desktop/MDI/NHSAdash')
runApp('Desktop/MDI/NHSAdash')
library(educationdata)
df <- get_education_data(level = "school-districts",
source = "ccd",
topic = "directory",
filters = list(year = 2021))
View(df)
shiny::runApp('Desktop/MDI/NHSAdash')
runApp('Desktop/MDI/NHSAdash')
View(df)
sum(is.na(df(,c('latitude','longitude')))
sum(is.na(df[,c('latitude','longitude')]))
shiny::runApp('Desktop/MDI/NHSAdash')
shiny::runApp('Desktop/MDI/NHSAdash')
shiny::runApp('Desktop/MDI/NHSAdash')
shiny::runApp('Desktop/MDI/NHSAdash')
install.packages("sf")
install.packages("sf")
runApp('Desktop/MDI/NHSAdash')
shiny::runApp('Desktop/MDI/NHSAdash')
# install.packages('educationdata')
library(educationdata)
library(dplyr)
df <- get_education_data(level = "school-districts",
source = "ccd",
topic = "directory",
filters = list(year = 2021))
df$latitude <- jitter(df$latitude)
df$longitude <- jitter(df$longitude)
df$zip_location <- formatC(df$zip_location, width=5, format="d", flag="0")
# convert urban_centric_locale to string values
df <- df %>%
mutate(locale = case_when(
urban_centric_locale == 11 ~ "City-Large",
urban_centric_locale == 12 ~ "City-Midsize",
urban_centric_locale == 13 ~ "City-Small",
urban_centric_locale == 21 ~ "Suburb-Large",
urban_centric_locale == 22 ~ "Suburb-Midsize",
urban_centric_locale == 23 ~ "Suburb-Small",
urban_centric_locale == 31 ~ "Town-Fringe",
urban_centric_locale == 32 ~ "Town-Distant",
urban_centric_locale == 33 ~ "Town-Remote",
urban_centric_locale == 41 ~ "Rural-Fringe",
urban_centric_locale == 42 ~ "Rural-Distant",
urban_centric_locale == 43 ~ "Rural-Remote",
TRUE ~ NA_character_
))
df <- df[,c('lea_name','city_location','county_name','state_location',
'zip_location','locale','lowest_grade_offered','highest_grade_offered',
'number_of_schools','enrollment','teachers_total_fte','latitude','longitude')]
# add pop and household income
# install.packages("zipcodeR")
library(zipcodeR)
districts = merge(x = df, y = zip_code_db[,c('zipcode','population','median_household_income')],
by.x='zip_location', by.y='zipcode', all.x = TRUE)
cleantable <- districts %>%
dplyr::select(
Name = lea_name,
City = city_location,
County = county_name,
State = state_location,
Zipcode = zip_location,
Population = population,
Income = median_household_income,
Locale = locale,
LowestGrade = lowest_grade_offered,
HighestGrade = highest_grade_offered,
NumSchools = number_of_schools,
TotalEnrollment = enrollment,
TotalTeachers = teachers_total_fte,
Lat = latitude,
Long = longitude
)
aggregated_hs <- cleantable %>%
group_by(County, State) %>%
summarise(TotalPopulation = sum(Population),
TotalIncome = sum(Income),
TotalNumSchools = sum(NumSchools),
SumTotalEnrollment = sum(TotalEnrollment),
SumTotalTeachers = sum(TotalTeachers),
AllLocale = toString(unique(Locale)),
.groups = "drop")
library(sp)
library(sf)
library(dplyr)
library(leaflet)
library(scales)
# download county shape file from Tiger
us.map <- st_read(dsn = "./tl_2023_us_county", layer = "tl_2023_us_county")
us.map <- st_read(dsn = "./Desktop/MDI/NHSAdash/tl_2023_us_county", layer = "tl_2023_us_county")
# Remove Alaska(2), Hawaii(15), Puerto Rico (72), Guam (66), Virgin Islands (78), American Samoa (60)
# Mariana Islands (69), Micronesia (64), Marshall Islands (68), Palau (70), Minor Islands (74)
us.map <- us.map[!us.map$STATEFP %in% c("02", "15", "72", "66", "78", "60", "69",
"64", "68", "70", "74"),]
# Make sure other outling islands are removed.
us.map <- us.map[!us.map$STATEFP %in% c("81", "84", "86", "87", "89", "71", "76",
"95", "79"),]
us.map <- us.map %>%
mutate(State = case_when(
STATEFP == "01" ~ "AL",
STATEFP == "04" ~ "AZ",
STATEFP == "05" ~ "AR",
STATEFP == "06" ~ "CA",
STATEFP == "08" ~ "CO",
STATEFP == "09" ~ "CT",
STATEFP == "10" ~ "DE",
STATEFP == "11" ~ "DC",
STATEFP == "12" ~ "FL",
STATEFP == "13" ~ "GA",
STATEFP == "16" ~ "ID",
STATEFP == "17" ~ "IL",
STATEFP == "18" ~ "IN",
STATEFP == "19" ~ "IA",
STATEFP == "20" ~ "KS",
STATEFP == "21" ~ "KY",
STATEFP == "22" ~ "LA",
STATEFP == "23" ~ "ME",
STATEFP == "24" ~ "MD",
STATEFP == "25" ~ "MA",
STATEFP == "26" ~ "MI",
STATEFP == "27" ~ "MN",
STATEFP == "28" ~ "MS",
STATEFP == "29" ~ "MO",
STATEFP == "30" ~ "MT",
STATEFP == "31" ~ "NE",
STATEFP == "32" ~ "NV",
STATEFP == "33" ~ "NH",
STATEFP == "34" ~ "NJ",
STATEFP == "35" ~ "NM",
STATEFP == "36" ~ "NY",
STATEFP == "37" ~ "NC",
STATEFP == "38" ~ "ND",
STATEFP == "39" ~ "OH",
STATEFP == "40" ~ "OK",
STATEFP == "41" ~ "OR",
STATEFP == "42" ~ "PA",
STATEFP == "43" ~ "PR",
STATEFP == "44" ~ "RI",
STATEFP == "45" ~ "SC",
STATEFP == "46" ~ "SD",
STATEFP == "47" ~ "TN",
STATEFP == "48" ~ "TX",
STATEFP == "49" ~ "UT",
STATEFP == "50" ~ "VT",
STATEFP == "51" ~ "VA",
STATEFP == "53" ~ "WA",
STATEFP == "54" ~ "WV",
STATEFP == "55" ~ "WI",
STATEFP == "56" ~ "WY",
TRUE ~ NA_character_
))
us.map <- us.map[,c('State','NAMELSAD','geometry')]
# Merge spatial df w aggregated data
merged_data <- left_join(us.map, aggregated_hs,
by = c("NAMELSAD" = "County", "State" = "State"))
merged_data <- st_transform(merged_data, 4326)
runApp('Desktop/MDI/NHSAdash')
shiny::runApp('Desktop/MDI/NHSAdash')
shiny::runApp('Desktop/MDI/NHSAdash')
library(greenR)
library(dplyr)
library(leaflet)
setwd("./Desktop/MDI/NHSAdash/")
source("get_green_data.R")
source("modified_visualizer.R")
## combine virginia counties
virginia_green_data <- get_green_data("Washington, D.C., United States")$osm_polygons
locations <- read.csv("va_counties.csv", header=F)$V1
for (location in locations) {
green_data <- get_green_data(location)
virginia_green_data <- bind_rows(virginia_green_data, green_data$osm_polygons)
}
modified_visualizer(virginia_green_data)
md_green_data <- get_green_data("Allegany County, Maryland, United States")$osm_polygons
md_loc <- read.csv("md_counties.csv", header=F)$V1
for (county in md_loc) {
green_data <- get_green_data(location)
md_green_data <- bind_rows(md_green_data, green_data$osm_polygons)
}
dmv_green_data <- bind_rows(virginia_green_data, md_green_data)
modified_visualizer(dmv_green_data)
modified_visualizer(dmv_green_data)
runApp()
